{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 28\n",
    "num_hidden = 128\n",
    "num_classes = 10\n",
    "learn_rate = 0.1\n",
    "batch_size = 128\n",
    "train_steps = 4300\n",
    "\n",
    "\n",
    "def RNN(x_dict,reuse):\n",
    "    with tf.variable_scope(\"RNN\",reuse=reuse):\n",
    "        x = x_dict[\"images\"]\n",
    "        x = tf.reshape(x,shape=[-1,28,28])\n",
    "\n",
    "        x = tf.unstack(x,num=timestep,axis=1)\n",
    "\n",
    "        rnn_cell = rnn.BasicLSTMCell(num_hidden,forget_bias=1.0)\n",
    "\n",
    "        outputs,states = rnn.static_rnn(rnn_cell,x,dtype=tf.float32)\n",
    "\n",
    "        out = tf.layers.dense(outputs[-1],num_classes)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def model_fn(features,labels,mode):\n",
    "    logit_train = RNN(features,reuse=False)\n",
    "    logit_test = RNN(features,reuse=True)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logit_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logit_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode,predictions=pred_classes)\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logit_train,\n",
    "                                                                            labels=tf.cast(labels,dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learn_rate)\n",
    "    train_op = optimizer.minimize(loss_op,global_step=tf.train.get_global_step())#,global_step=tf.train.get_global_step()\n",
    "                             \n",
    "    acc_op = tf.metrics.accuracy(labels=labels,predictions=pred_classes)\n",
    "    \n",
    "    estim_spec = tf.estimator.EstimatorSpec(mode,predictions=pred_classes,loss=loss_op,train_op=train_op,eval_metric_ops={\"accuracy\":acc_op})\n",
    "    \n",
    "    return estim_spec\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000013C8E199F98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn,model_dir=\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-9af14e3f9e74>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\anconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\anconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../Data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\anconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../Data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../Data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\anconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../Data/mnist\",one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 500\n",
    "test_images = mnist.test.images[i]\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(np.reshape(test_images, [28, 28]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "mnist.test.labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3122883, step = 1\n",
      "INFO:tensorflow:global_step/sec: 22.0342\n",
      "INFO:tensorflow:loss = 1.6221787, step = 101 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2989\n",
      "INFO:tensorflow:loss = 1.1898363, step = 201 (3.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5378\n",
      "INFO:tensorflow:loss = 0.7308013, step = 301 (3.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.2861\n",
      "INFO:tensorflow:loss = 0.6682602, step = 401 (3.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3952\n",
      "INFO:tensorflow:loss = 0.5495979, step = 501 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.744\n",
      "INFO:tensorflow:loss = 0.54046184, step = 601 (4.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0522\n",
      "INFO:tensorflow:loss = 0.34690964, step = 701 (4.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3329\n",
      "INFO:tensorflow:loss = 0.122813106, step = 801 (4.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3211\n",
      "INFO:tensorflow:loss = 0.35083595, step = 901 (4.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5117\n",
      "INFO:tensorflow:loss = 0.20520258, step = 1001 (3.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3823\n",
      "INFO:tensorflow:loss = 0.15384299, step = 1101 (3.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5052\n",
      "INFO:tensorflow:loss = 0.09161575, step = 1201 (3.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7553\n",
      "INFO:tensorflow:loss = 0.120854706, step = 1301 (4.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.006\n",
      "INFO:tensorflow:loss = 0.119899124, step = 1401 (4.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4081\n",
      "INFO:tensorflow:loss = 0.10997838, step = 1501 (3.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.784\n",
      "INFO:tensorflow:loss = 0.16135985, step = 1601 (4.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.1587\n",
      "INFO:tensorflow:loss = 0.15595068, step = 1701 (4.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3152\n",
      "INFO:tensorflow:loss = 0.15193065, step = 1801 (4.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9543\n",
      "INFO:tensorflow:loss = 0.09029164, step = 1901 (4.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.434\n",
      "INFO:tensorflow:loss = 0.08646928, step = 2001 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4858\n",
      "INFO:tensorflow:loss = 0.12973091, step = 2101 (3.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6952\n",
      "INFO:tensorflow:loss = 0.1656354, step = 2201 (3.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4987\n",
      "INFO:tensorflow:loss = 0.08172491, step = 2301 (3.922 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.6385\n",
      "INFO:tensorflow:loss = 0.043782856, step = 2401 (4.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9768\n",
      "INFO:tensorflow:loss = 0.07849184, step = 2501 (4.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4081\n",
      "INFO:tensorflow:loss = 0.12025761, step = 2601 (3.938 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3823\n",
      "INFO:tensorflow:loss = 0.058711365, step = 2701 (3.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5298\n",
      "INFO:tensorflow:loss = 0.104382515, step = 2801 (4.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7778\n",
      "INFO:tensorflow:loss = 0.19060951, step = 2901 (4.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1969\n",
      "INFO:tensorflow:loss = 0.0044494793, step = 3001 (3.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4459\n",
      "INFO:tensorflow:loss = 0.07478143, step = 3101 (4.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.5835\n",
      "INFO:tensorflow:loss = 0.11118197, step = 3201 (3.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4922\n",
      "INFO:tensorflow:loss = 0.14978784, step = 3301 (3.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0637\n",
      "INFO:tensorflow:loss = 0.10078279, step = 3401 (4.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.4469\n",
      "INFO:tensorflow:loss = 0.0877795, step = 3501 (3.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.682\n",
      "INFO:tensorflow:loss = 0.08696252, step = 3601 (3.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8219\n",
      "INFO:tensorflow:loss = 0.0806814, step = 3701 (4.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9955\n",
      "INFO:tensorflow:loss = 0.051215243, step = 3801 (4.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.434\n",
      "INFO:tensorflow:loss = 0.07209925, step = 3901 (3.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1906\n",
      "INFO:tensorflow:loss = 0.02812922, step = 4001 (3.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3566\n",
      "INFO:tensorflow:loss = 0.08606665, step = 4101 (3.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.421\n",
      "INFO:tensorflow:loss = 0.119456634, step = 4201 (3.934 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4300 into ./model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.09247063.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x13c8e199e48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={\"images\":mnist.train.images},y=mnist.train.labels,batch_size=batch_size,shuffle=False,num_epochs=None)\n",
    "model.train(input_fn,steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-23-08:16:51\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model\\model.ckpt-4300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-23-08:16:52\n",
      "INFO:tensorflow:Saving dict for global step 4300: accuracy = 0.9772, global_step = 4300, loss = 0.072746314\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4300: ./model\\model.ckpt-4300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9772, 'loss': 0.072746314, 'global_step': 4300}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(x={\"images\":mnist.test.images},y=mnist.test.labels,batch_size=batch_size,shuffle=False)\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
